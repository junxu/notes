## GAN papers


1. RSGAN[2018] [The relativistic discriminator: a key element missing from standard GAN](https://arxiv.org/abs/1807.00734) []
2. Progressive GAN[2017] [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196)
3. GAN stability[2018] [Which Training Methods for GANs do actually Converge?](https://arxiv.org/abs/1801.04406)
4. IntroVAE[2018] [IntroVAE: Introspective Variational Autoencoders for Photographic Image Synthesis](https://arxiv.org/abs/1807.06358) 
5. BigGAN[2018] [Large Scale GAN Training for High Fidelity Natural Image Synthesis](https://arxiv.org/abs/1809.11096)
6. [2018] [Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow](https://arxiv.org/abs/1810.00821)
7. [2018] [A Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/abs/1812.04948)
8. [2017] [Stabilizing Training of Generative Adversarial Networks through Regularization](https://arxiv.org/abs/1705.09367)
9. [2017] [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500)
10. [2018] [Spectral Normalization for Generative Adversarial Networks](https://arxiv.org/abs/1802.05957)
11. [2018] [Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect](https://arxiv.org/abs/1803.01541)

